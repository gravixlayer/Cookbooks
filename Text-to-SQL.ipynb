{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "text-to-sql-cookbook",
   "metadata": {},
   "source": [
    "# Gravix Layer Cookbook: Text-to-SQL Multi-Agent System\n",
    "\n",
    "Welcome to the Gravix Layer Cookbook series. This guide demonstrates building a multi-agent system that converts natural language questions into SQL queries and provides insightful analysis of the results, leveraging Gravix Layer's AI capabilities.\n",
    "\n",
    "## Vision\n",
    "\n",
    "Imagine asking questions about your data in plain English and receiving accurate, actionable insights instantly, without writing SQL or understanding database schemas. This system transforms natural language into precise database queries and meaningful results through intelligent agent collaboration.\n",
    "\n",
    "## Solution\n",
    "\n",
    "The system uses four specialized AI agents:\n",
    "- **Database Context Analyst**: Understands data structure and relationships\n",
    "- **SQL Query Specialist**: Converts natural language to SQL queries\n",
    "- **Query Execution Specialist**: Safely executes queries with validation\n",
    "- **Data Analysis Specialist**: Interprets results for human-readable insights\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "This recipe provides a production-ready text-to-SQL system:\n",
    "- Multi-agent workflow with specialized AI components\n",
    "- Secure SQLite database interaction\n",
    "- Interactive query interface with formatted results\n",
    "- Robust error handling and validation\n",
    "- Sample dataset for testing\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Basic SQL and database knowledge\n",
    "- Gravix Layer API access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Install required libraries and configure the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-dependencies",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-packages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"openai>=1.0.0\" \"pandas>=1.5.0\" \"python-dotenv>=0.19.0\" \"langchain\" --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "import-libs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, Optional\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import getpass\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configure-client",
   "metadata": {},
   "source": [
    "## 2. Configure Gravix Layer Client\n",
    "\n",
    "Set up the Gravix Layer API client with secure API key handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "client-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravix Layer client configured.\n"
     ]
    }
   ],
   "source": [
    "#GET YOUR GRAVIXLAYER_API_KEY FROM https://platform.gravixlayer.com/\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GRAVIXLAYER_API_KEY\") or getpass.getpass(\"Enter Gravix Layer API key: \")\n",
    "os.environ[\"GRAVIXLAYER_API_KEY\"] = api_key\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.gravixlayer.com/v1/inference\",\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "print(\"Gravix Layer client configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-creation",
   "metadata": {},
   "source": [
    "## 3. Sample Dataset Creation\n",
    "\n",
    "Create a sample customer sales database for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "create-dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created with table 'customer_sales_data'.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'customer_id': [1, 1, 2, 3, 3, 3, 4, 5, 5],\n",
    "    'customer_name': ['Alice', 'Alice', 'Bob', 'Charlie', 'Charlie', 'Charlie', 'David', 'Eve', 'Eve'],\n",
    "    'product_name': ['Laptop', 'Mouse', 'Desk Chair', 'Laptop', 'Keyboard', 'Monitor', 'Mouse', 'Tablet', 'Headphones'],\n",
    "    'category': ['Electronics', 'Electronics', 'Furniture', 'Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics'],\n",
    "    'price': [1200, 25, 150, 1250, 75, 300, 30, 800, 120],\n",
    "    'quantity': [1, 2, 1, 1, 1, 2, 3, 1, 2],\n",
    "    'order_date': ['2023-02-20', '2023-02-21', '2023-04-01', '2023-06-01', '2023-06-01', '2024-01-05', '2024-03-15', '2024-02-10', '2024-02-10']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['total_amount'] = df['price'] * df['quantity']\n",
    "\n",
    "db_filename = 'sales_data.db'\n",
    "conn = sqlite3.connect(db_filename)\n",
    "cursor = conn.cursor()\n",
    "table_name = 'customer_sales_data'\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Database created with table 'customer_sales_data'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "database-tools",
   "metadata": {},
   "source": [
    "## 4. Database Tools\n",
    "\n",
    "Implement secure database interaction tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "database-tools-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database tools initialized.\n"
     ]
    }
   ],
   "source": [
    "class DatabaseTools:\n",
    "    def __init__(self, cursor, table_name):\n",
    "        self.cursor = cursor\n",
    "        self.table_name = table_name\n",
    "    \n",
    "    def get_context(self):\n",
    "        try:\n",
    "            self.cursor.execute(f\"PRAGMA table_info({self.table_name});\")\n",
    "            columns = self.cursor.fetchall()\n",
    "            schema_info = \"Schema (Column Name: Data Type):\\n\"\n",
    "            for col in columns:\n",
    "                schema_info += f\"  - {col[1]}: {col[2]}\\n\"\n",
    "            \n",
    "            self.cursor.execute(f\"SELECT * FROM {self.table_name} LIMIT 5;\")\n",
    "            sample_rows = self.cursor.fetchall()\n",
    "            headers = [desc[0] for desc in self.cursor.description]\n",
    "            sample_data = \"\\nSample Data (First 5 Rows):\\n\" + f\"{', '.join(headers)}\\n\"\n",
    "            for row in sample_rows:\n",
    "                sample_data += f\"{', '.join(map(str, row))}\\n\"\n",
    "            \n",
    "            return f\"Table '{self.table_name}':\\n{schema_info}{sample_data}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error getting context: {str(e)}\"\n",
    "    \n",
    "    def execute_query(self, sql_query):\n",
    "        try:\n",
    "            if not sql_query.strip().upper().startswith('SELECT'):\n",
    "                return \"Error: Only SELECT queries permitted.\"\n",
    "            self.cursor.execute(sql_query)\n",
    "            results = self.cursor.fetchall()\n",
    "            if not results:\n",
    "                return \"Query returned no results.\"\n",
    "            \n",
    "            headers = [desc[0] for desc in self.cursor.description]\n",
    "            result_str = f\"Columns: {', '.join(headers)}\\n\"\n",
    "            for i, row in enumerate(results[:20]):\n",
    "                result_str += f\"Row {i+1}: {', '.join(map(str, row))}\\n\"\n",
    "            if len(results) > 20:\n",
    "                result_str += f\"... and {len(results) - 20} more rows.\"\n",
    "            return result_str\n",
    "        except Exception as e:\n",
    "            return f\"Error executing query: {str(e)}\\nQuery: {sql_query}\"\n",
    "\n",
    "db_tools = DatabaseTools(cursor, table_name)\n",
    "print(\"Database tools initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi-agent-system",
   "metadata": {},
   "source": [
    "## 5. Multi-Agent System\n",
    "\n",
    "Implement the four specialized AI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context-agent",
   "metadata": {},
   "source": [
    "### 5.1 Database Context Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "context-agent-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseContextAgent:\n",
    "    def __init__(self, llm, db_tools):\n",
    "        self.db_tools = db_tools\n",
    "        self.context_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"You are a database analyst providing actionable insights.\"),\n",
    "                (\"human\", \"\"\"Database Context:\\n{raw_context}\\n\\nUser Question: {user_question}\\n\\nProvide:\\n1. Relevant columns\\n2. Important data relationships\\n3. Potential challenges\"\"\")\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    def analyze_context(self, user_question):\n",
    "        raw_context = self.db_tools.get_context()\n",
    "        try:\n",
    "            response = self.context_chain.invoke({\"raw_context\": raw_context, \"user_question\": user_question})\n",
    "            analysis = response[\"text\"]\n",
    "            return {\"raw_context\": raw_context, \"analysis\": analysis}\n",
    "        except Exception as e:\n",
    "            return {\"raw_context\": raw_context, \"analysis\": \"Error in context analysis: \" + str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sql-agent",
   "metadata": {},
   "source": [
    "### 5.2 SQL Query Specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sql-agent-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLQueryAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.sql_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"You are a SQL expert. Return only executable SQL code.\"),\n",
    "                (\"human\", \"\"\"Database Context:\\n{raw_context}\\n\\nContext Analysis:\\n{analysis}\\n\\nUser Question: {user_question}\\n\\nWrite a precise SQL query to answer the question. Return only SQL code.\"\"\")\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    def generate_query(self, user_question, context_data):\n",
    "        try:\n",
    "            response = self.sql_chain.invoke({\n",
    "                \"raw_context\": context_data[\"raw_context\"],\n",
    "                \"analysis\": context_data[\"analysis\"],\n",
    "                \"user_question\": user_question\n",
    "            })\n",
    "            sql_query = response[\"text\"].strip().replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "            return {\"sql_query\": sql_query}\n",
    "        except Exception as e:\n",
    "            return {\"sql_query\": None, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "execution-agent",
   "metadata": {},
   "source": [
    "### 5.3 Query Execution Specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "execution-agent-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExecutionAgent:\n",
    "    def __init__(self, db_tools):\n",
    "        self.db_tools = db_tools\n",
    "    \n",
    "    def execute_query(self, query_data):\n",
    "        if query_data.get('error'):\n",
    "            return {\"error\": f\"Cannot execute query: {query_data['error']}\"}\n",
    "        sql_query = query_data['sql_query']\n",
    "        if not sql_query:\n",
    "            return {\"error\": \"No SQL query provided.\"}\n",
    "        results = self.db_tools.execute_query(sql_query)\n",
    "        return {\"results\": results, \"sql_query\": sql_query}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-agent",
   "metadata": {},
   "source": [
    "### 5.4 Data Analysis Specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "analysis-agent-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAnalysisAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.analysis_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"You are a data analyst providing clear insights.\"),\n",
    "                (\"human\", \"\"\"Question: {user_question}\\n\\nSQL Query: {sql_query}\\n\\nResults: {results}\\n\\nProvide a clear, human-readable answer that:\\n1. Answers the question\\n2. Highlights key insights\\n3. Uses specific numbers\\n4. Is accessible to non-technical users\"\"\")\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    def analyze_results(self, user_question, execution_data):\n",
    "        if execution_data.get('error'):\n",
    "            return {\"analysis\": f\"Analysis failed: {execution_data['error']}\"}\n",
    "        try:\n",
    "            response = self.analysis_chain.invoke({\n",
    "                \"user_question\": user_question,\n",
    "                \"sql_query\": execution_data['sql_query'],\n",
    "                \"results\": execution_data['results']\n",
    "            })\n",
    "            return {\"analysis\": response[\"text\"]}\n",
    "        except Exception as e:\n",
    "            return {\"analysis\": \"Query executed, but analysis failed. Review raw results.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinator",
   "metadata": {},
   "source": [
    "## 6. Multi-Agent Coordinator\n",
    "\n",
    "Orchestrate the agents to process queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinator-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentCoordinator:\n",
    "    def __init__(self, db_tools):\n",
    "        context_llm = ChatOpenAI(\n",
    "            openai_api_key=os.environ[\"GRAVIXLAYER_API_KEY\"],\n",
    "            openai_api_base=\"https://api.gravixlayer.com/v1/inference\",\n",
    "            model=\"meta-llama/llama-3.1-8b-instruct\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        sql_llm = ChatOpenAI(\n",
    "            openai_api_key=os.environ[\"GRAVIXLAYER_API_KEY\"],\n",
    "            openai_api_base=\"https://api.gravixlayer.com/v1/inference\",\n",
    "            model=\"meta-llama/llama-3.1-8b-instruct\",\n",
    "            temperature=0.1,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        analysis_llm = ChatOpenAI(\n",
    "            openai_api_key=os.environ[\"GRAVIXLAYER_API_KEY\"],\n",
    "            openai_api_base=\"https://api.gravixlayer.com/v1/inference\",\n",
    "            model=\"meta-llama/llama-3.1-8b-instruct\",\n",
    "            temperature=0.3,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        self.context_agent = DatabaseContextAgent(context_llm, db_tools)\n",
    "        self.sql_agent = SQLQueryAgent(sql_llm)\n",
    "        self.execution_agent = QueryExecutionAgent(db_tools)\n",
    "        self.analysis_agent = ResultAnalysisAgent(analysis_llm)\n",
    "        print(\"Multi-agent system initialized.\")\n",
    "    \n",
    "    def process_query(self, user_question):\n",
    "        start_time = datetime.now()\n",
    "        context_data = self.context_agent.analyze_context(user_question)\n",
    "        query_data = self.sql_agent.generate_query(user_question, context_data)\n",
    "        execution_data = self.execution_agent.execute_query(query_data)\n",
    "        analysis_data = self.analysis_agent.analyze_results(user_question, execution_data)\n",
    "        processing_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        return {\n",
    "            \"success\": not execution_data.get(\"error\"),\n",
    "            \"question\": user_question,\n",
    "            \"context_analysis\": context_data.get(\"analysis\", \"\"),\n",
    "            \"sql_query\": execution_data.get(\"sql_query\", query_data.get(\"sql_query\", \"\")),\n",
    "            \"results\": execution_data.get(\"results\", \"\"),\n",
    "            \"analysis\": analysis_data.get(\"analysis\", \"\"),\n",
    "            \"processing_time\": processing_time\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-interface",
   "metadata": {},
   "source": [
    "## 7. Query Interface\n",
    "\n",
    "Provide a function to process queries and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "query-interface-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-SQL system ready.\n"
     ]
    }
   ],
   "source": [
    "def text_to_sql_query(user_question, db_tools):\n",
    "    coordinator = MultiAgentCoordinator(db_tools)\n",
    "    return coordinator.process_query(user_question)\n",
    "\n",
    "def display_results(result):\n",
    "    print(\"\\nQuery Results\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Processing Time: {result.get('processing_time', 0):.2f} seconds\")\n",
    "    print(\"\\nAnalysis:\")\n",
    "    print(result['analysis'])\n",
    "    print(\"\\nSQL Query:\")\n",
    "    print(result['sql_query'])\n",
    "    print(\"\\nRaw Results:\")\n",
    "    print(result['results'])\n",
    "\n",
    "print(\"Text-to-SQL system ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo",
   "metadata": {},
   "source": [
    "## 8. Demonstration\n",
    "\n",
    "Test the system with example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demo-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstration: Text-to-SQL Queries\n",
      "\n",
      "Query: How much has each customer spent in total?\n",
      "Multi-agent system initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/5cm6cfms4qv436j8t8m9_tf00000gn/T/ipykernel_14416/650229414.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  context_llm = ChatOpenAI(\n",
      "/var/folders/z2/5cm6cfms4qv436j8t8m9_tf00000gn/T/ipykernel_14416/1547614311.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  self.context_chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Results\n",
      "----------------------------------------\n",
      "Question: How much has each customer spent in total?\n",
      "Processing Time: 18.22 seconds\n",
      "\n",
      "Analysis:\n",
      "Here's the answer:\n",
      "\n",
      "**Total Spending by Each Customer**\n",
      "\n",
      "Based on our analysis of customer sales data, here's how much each customer has spent in total:\n",
      "\n",
      "* **Customer 1**: Spent a total of **$1250**\n",
      "* **Customer 2**: Spent a total of **$150**\n",
      "* **Customer 3**: Spent a total of **$1925**\n",
      "* **Customer 4**: Spent a total of **$90**\n",
      "* **Customer 5**: Spent a total of **$1040**\n",
      "\n",
      "**Key Insights:**\n",
      "\n",
      "* Customer 1 has spent the most, with a total of $1250.\n",
      "* Customers 3 and 5 are among the biggest spenders, with totals of $1925 and $1040 respectively.\n",
      "* Customers 2 and 4 have spent relatively little, with totals of just $150 and $90.\n",
      "\n",
      "These insights can help businesses identify their most valuable customers and tailor marketing efforts to retain them.\n",
      "\n",
      "SQL Query:\n",
      "\n",
      "SELECT \n",
      "  customer_id,\n",
      "  SUM(total_amount) AS total_spent\n",
      "FROM \n",
      "  customer_sales_data\n",
      "GROUP BY \n",
      "  customer_id;\n",
      "\n",
      "\n",
      "Raw Results:\n",
      "Columns: customer_id, total_spent\n",
      "Row 1: 1, 1250\n",
      "Row 2: 2, 150\n",
      "Row 3: 3, 1925\n",
      "Row 4: 4, 90\n",
      "Row 5: 5, 1040\n",
      "\n",
      "\n",
      "========================================\n",
      "Query: What is the average order value by product category?\n",
      "Multi-agent system initialized.\n",
      "\n",
      "Query Results\n",
      "----------------------------------------\n",
      "Question: What is the average order value by product category?\n",
      "Processing Time: 15.94 seconds\n",
      "\n",
      "Analysis:\n",
      "**Average Order Value by Product Category**\n",
      "\n",
      "Our analysis reveals that customers spend significantly more on electronics compared to furniture.\n",
      "\n",
      "* The average order value for electronics is **$538.13**, indicating that customers tend to make larger purchases in this category.\n",
      "* In contrast, the average order value for furniture is **$150.00**, suggesting that customers typically buy smaller quantities of furniture items.\n",
      "\n",
      "These findings can inform marketing strategies and product offerings to better cater to customer preferences. For instance, electronics retailers may consider offering bundle deals or promotions to encourage even higher average order values, while furniture stores could explore ways to upsell or cross-sell complementary products to increase the average order value in this category.\n",
      "\n",
      "SQL Query:\n",
      "\n",
      "SELECT \n",
      "  category,\n",
      "  AVG(total_amount) AS avg_order_value\n",
      "FROM \n",
      "  customer_sales_data\n",
      "GROUP BY \n",
      "  category;\n",
      "\n",
      "\n",
      "Raw Results:\n",
      "Columns: category, avg_order_value\n",
      "Row 1: Electronics, 538.125\n",
      "Row 2: Furniture, 150.0\n",
      "\n",
      "\n",
      "========================================\n",
      "Query: Show me all electronics purchases over $100\n",
      "Multi-agent system initialized.\n",
      "\n",
      "Query Results\n",
      "----------------------------------------\n",
      "Question: Show me all electronics purchases over $100\n",
      "Processing Time: 18.12 seconds\n",
      "\n",
      "Analysis:\n",
      "**Electronics Purchases Over $100**\n",
      "\n",
      "Based on our analysis of customer sales data, here are all electronics purchases made by customers where the total amount spent exceeds $100:\n",
      "\n",
      "* **Alice**: Bought a Laptop for a total of **$1200**\n",
      "* **Charlie**: Made two separate purchases:\n",
      "\t+ A Laptop for a total of **$1250**\n",
      "\t+ A Monitor for a total of **$600** (note: this purchase is below the $100 threshold, but included in the results as it was part of Charlie's overall electronics spending)\n",
      "* **Eve**: Purchased two items:\n",
      "\t+ A Tablet for a total of **$800**\n",
      "\t+ Headphones for a total of **$240**\n",
      "\n",
      "Key Insights:\n",
      "\n",
      "* The majority of electronics purchases over $100 were made by Alice and Charlie, who spent a significant amount on laptops.\n",
      "* Eve's purchases also exceeded the $100 threshold, with a tablet being the most expensive item purchased.\n",
      "\n",
      "These results provide a clear picture of which customers have made substantial electronics purchases.\n",
      "\n",
      "SQL Query:\n",
      "\n",
      "SELECT \n",
      "  customer_name,\n",
      "  product_name,\n",
      "  price * quantity AS total_amount\n",
      "FROM \n",
      "  customer_sales_data\n",
      "WHERE \n",
      "  category = 'Electronics' AND \n",
      "  (price * quantity) > 100;\n",
      "\n",
      "\n",
      "Raw Results:\n",
      "Columns: customer_name, product_name, total_amount\n",
      "Row 1: Alice, Laptop, 1200\n",
      "Row 2: Charlie, Laptop, 1250\n",
      "Row 3: Charlie, Monitor, 600\n",
      "Row 4: Eve, Tablet, 800\n",
      "Row 5: Eve, Headphones, 240\n",
      "\n",
      "\n",
      "========================================\n",
      "Query: Which customer bought the most expensive item?\n",
      "Multi-agent system initialized.\n",
      "\n",
      "Query Results\n",
      "----------------------------------------\n",
      "Question: Which customer bought the most expensive item?\n",
      "Processing Time: 17.42 seconds\n",
      "\n",
      "Analysis:\n",
      "Here's the answer:\n",
      "\n",
      "**The customer who bought the most expensive item is Charlie**, who purchased a **Laptop for $1250**.\n",
      "\n",
      "Some interesting observations from the data:\n",
      "\n",
      "* Charlie also bought other items, including a Monitor ($300) and a Keyboard ($75), but the Laptop was by far his most expensive purchase.\n",
      "* Alice bought two items: a Laptop ($1200) and a Mouse ($25). Her total spend on these items is $1225.\n",
      "* Eve purchased three items: a Tablet ($800), Headphones ($120), and a Mouse ($30). Her total spend on these items is $950.\n",
      "\n",
      "Overall, Charlie's purchase of the Laptop stands out as the most expensive item in the dataset.\n",
      "\n",
      "SQL Query:\n",
      "\n",
      "SELECT \n",
      "  csd.customer_name, \n",
      "  MAX(csd.price) AS max_price,\n",
      "  csd.product_name\n",
      "FROM \n",
      "  customer_sales_data csd\n",
      "GROUP BY \n",
      "  csd.customer_id, csd.product_name\n",
      "ORDER BY \n",
      "  max_price DESC;\n",
      "\n",
      "\n",
      "Raw Results:\n",
      "Columns: customer_name, max_price, product_name\n",
      "Row 1: Charlie, 1250, Laptop\n",
      "Row 2: Alice, 1200, Laptop\n",
      "Row 3: Eve, 800, Tablet\n",
      "Row 4: Charlie, 300, Monitor\n",
      "Row 5: Bob, 150, Desk Chair\n",
      "Row 6: Eve, 120, Headphones\n",
      "Row 7: Charlie, 75, Keyboard\n",
      "Row 8: David, 30, Mouse\n",
      "Row 9: Alice, 25, Mouse\n",
      "\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Demonstration: Text-to-SQL Queries\\n\")\n",
    "\n",
    "questions = [\n",
    "    \"How much has each customer spent in total?\",\n",
    "    \"What is the average order value by product category?\",\n",
    "    \"Show me all electronics purchases over $100\",\n",
    "    \"Which customer bought the most expensive item?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Query: {question}\")\n",
    "    result = text_to_sql_query(question, db_tools)\n",
    "    display_results(result)\n",
    "    print(\"\\n\" + \"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "This cookbook delivers a production-ready text-to-SQL system powered by Gravix Layer:\n",
    "- **Multi-Agent Architecture**: Four specialized AI agents for accurate query processing\n",
    "- **Secure Database Access**: SELECT-only queries with validation\n",
    "- **Intelligent Analysis**: Context-aware query generation and human-readable insights\n",
    "- **Robust Design**: Comprehensive error handling\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Context-Aware**: Analyzes database structure for precise queries\n",
    "- **Secure**: Restricts queries to SELECT statements\n",
    "- **Accessible**: Provides clear insights for non-technical users\n",
    "- **Extensible**: Easily adaptable for additional functionality\n",
    "\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Agent specialization enhances query accuracy\n",
    "- Security validation ensures safe database interactions\n",
    "- Context analysis enables intelligent query generation\n",
    "- Human-readable output makes data accessible\n",
    "\n",
    "You've built a powerful text-to-SQL system with Gravix Layer, ready to transform natural language into actionable database insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
